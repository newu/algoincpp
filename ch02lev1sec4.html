<html><head><title>2.4. Big-Oh Notation</title><title>TeamUnknown</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8" /><link rel="STYLESHEET" type="text/css" href="portals/bvdep/xsltemplates/globalstyle.css" /><link href="includes/searchResults.css" rel="stylesheet" type="text/css" /><link rel="STYLESHEET" type="text/css" href="portals/bvdep/xsltemplates/style.css" /><link rel="STYLESHEET" type="text/css" href="portals/bvdep/xsltemplates/docsafari.css" /><body><table width="100%" border="0" cellspacing="0" cellpadding="0"><td class="docBookTitle"><a href="toc.html"><b>[ Team Unknown ]</b></a></td></table><td align="center"><a name="MainContent"></a><table width="95%"><tr><td align="left" class="v2"><!--Copyright (c) 2002 Safari Tech Books Online--><table width="100%" border="0" cellspacing="0" cellpadding="2"><tr><td valign="middle" class="v2" height="5"><img src="pixel.gif" width="1" height="5" alt="" border="0" /></td></tr><tr><td valign="middle" class="v2"><table cellpadding="0" cellspacing="0" border="0" width="100%"><tr><td align="left"><span style="white-space:nowrap">&nbsp;</span>
                  &nbsp;
                  <span style="white-space:nowrap"> &nbsp;&nbsp;</span>
            &nbsp;<span style="white-space:nowrap">&nbsp;</span></td></tr></table></td><td></td><td valign="middle" class="v2" align="right"> 
          &nbsp;
          <span style="white-space:nowrap"><a target="_self" href="ch02lev1sec3.html" title="Previous section"><img border="0" align="absmiddle" src="btn_prev.gif" alt="Previous section" id="btn_prev" /></a></span>
				
				&nbsp;
				
				<span style="white-space:nowrap"><a target="_self" href="ch02lev1sec5.html" title="Next section"><img border="0" align="absmiddle" src="btn_next.gif" alt="Next section" id="btn_next" /></a></span></td></tr></table><div id="section"><br /><table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top">C++ Programming Robert Sedgewick - Princeton University Addison Wesley Professional Algorithms in C++, Parts 1&ndash;4: Fundamentals, Data Structure, Sorting, Searching, Third Edition<a name="ch02lev1sec4"></a>
<h3 id="title-IDA1L3ZM" class="docSection1Title">2.4. Big-Oh Notation</h3>
<p class="docText">The mathematical artifact that allows us to suppress detail when we are analyzing algorithms is called the <span class="docEmphasis">O-notation</span>, or &quot;big-Oh notation,&quot; which is defined as follows.</p>
<a name="ch02ex01"></a><h5 id="title-IDAPM3ZM" class="docExampleTitle">Definition 2.1. A function <span class="docEmphasis">g</span> (<span class="docEmphasis">N</span>) is said to be <span class="docEmphasis">O</span>(<span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>)) if there exist constants <span class="docEmphasis">c</span><sub>0</sub> and <span class="docEmphasis">N</span><sub>0</sub> such that <span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>) &lt; <span class="docEmphasis">c</span><sub>0</sub> <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>) for all <span class="docEmphasis">N</span> &gt; <span class="docEmphasis">N</span><sub>0</sub></h5><p><table cellspacing="0" width="90%" border="1" cellpadding="5"><tr><td>
<p class="docText">We use the <span class="docEmphasis">O</span>-notation for three distinct purposes:</p>
<ul><li><p class="docList">To bound the error that we make when we ignore small terms in mathematical formulas</p></li><li><p class="docList">To bound the error that we make when we ignore parts of a program that contribute a small amount to the total being analyzed</p></li><li><p class="docList">To allow us to classify algorithms according to upper bounds on their total running times</p></li></ul>
<p class="docText">We consider the third use in <a class="docLink" href="ch02lev1sec7.html#ch02lev1sec7">Section 2.7</a>, and discuss briefly the other two here.</p>
<p class="docText">The constants <span class="docEmphasis">c</span><sub>0</sub> and <span class="docEmphasis">N</span><sub>0</sub> implicit in the <span class="docEmphasis">O</span>-notation often hide implementation details that are important in practice. Obviously, saying that an algorithm has running time <span class="docEmphasis">O</span>(<span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>)) says nothing about the running time if <span class="docEmphasis">N</span> happens to be less than <span class="docEmphasis">N</span><sub>0</sub>, and <span class="docEmphasis">c</span><sub>0</sub> might be hiding a large amount of overhead designed to avoid a bad worst case.</p>
<p class="docText"><a name="iddle1102"></a><a name="iddle1987"></a><a name="iddle1990"></a>We would prefer an algorithm using <span class="docEmphasis">N</span><sup>2</sup> nanoseconds over one using <span class="docEmphRoman">log</span> <span class="docEmphasis">N</span> centuries, but we could not make this choice on the basis of the <span class="docEmphasis">O</span>-notation.</p>
<p class="docText">Often, the results of a mathematical analysis are not exact, but rather are approximate in a precise technical sense: The result might be an expression consisting of a sequence of decreasing terms. Just as we are most concerned with the inner loop of a program, we are most concerned with the <span class="docEmphasis">leading terms</span> (the largest terms) of a mathematical expression. The <span class="docEmphasis">O</span>-notation allows us to keep track of the leading terms while ignoring smaller terms when manipulating approximate mathematical expressions, and ultimately allows us to make concise statements that give accurate approximations to the quantities that we analyze.</p>
<p class="docText">Some of the basic manipulations that we use when working with expressions containing the <span class="docEmphasis">O</span>-notation are the subject of <a class="docLink" href="#ch02qa4q1">Exercises 2.20</a> through <a class="docLink" href="#ch02qa4q6">2.25</a>. Many of these manipulations are intuitive, but mathematically inclined readers may be interested in working <a class="docLink" href="#ch02qa4q2">Exercise 2.21</a> to prove the validity of the basic operations from the definition. Essentially, these exercises say that we can expand algebraic expressions using the <span class="docEmphasis">O</span>-notation as though the <span class="docEmphasis">O</span> were not there, then can drop all but the largest term. For example, if we expand the expression</p>
<div class="docText"><pre>(<span class="docEmphasis">N</span>+ <span class="docEmphasis">O</span>(1))(<span class="docEmphasis">N</span> + <span class="docEmphasis">O</span>(log <span class="docEmphasis">N</span>) + <span class="docEmphasis">O</span>(1)),</pre></div><br />
<p class="docText">we get six terms</p>
<div class="docText"><pre><span class="docEmphasis">N</span><sup>2</sup> + <span class="docEmphasis">O</span>(<span class="docEmphasis">N</span>) + <span class="docEmphasis">O</span>(<span class="docEmphasis">N</span> log <span class="docEmphasis">N</span>) + <span class="docEmphasis">O</span>(log <span class="docEmphasis">N</span>) + <span class="docEmphasis">O</span>(<span class="docEmphasis">N</span>) + <span class="docEmphasis">O</span>(1),</pre></div><br />
<p class="docText">but can drop all but the largest <span class="docEmphasis">O</span>-term, leaving the approximation</p>
<div class="docText"><pre><span class="docEmphasis">N</span><sup>2</sup> + <span class="docEmphasis">O</span>(<span class="docEmphasis">N</span>log<span class="docEmphasis">N</span>).</pre></div><br />
<p class="docText">That is, <span class="docEmphasis">N</span><sup>2</sup> is a good approximation to this expression when <span class="docEmphasis">N</span> is large. These manipulations are intuitive, but the <span class="docEmphasis">O</span>-notation allows us to express them mathematically with rigor and precision. We refer to a formula with one <span class="docEmphasis">O</span>-term as an <span class="docEmphasis">asymptotic expression</span>.</p>
<p class="docText">For a more relevant example, suppose that (after some mathematical analysis) we determine that a particular algorithm has an inner loop that is iterated <span class="docEmphasis">NH<sub>N</sub></span> times on the average, an outer section that is iterated <span class="docEmphasis">N</span> times, and some initialization code that is executed once.</p>
<p class="docText"><a name="iddle1384"></a><a name="iddle1934"></a><a name="iddle1991"></a><a name="iddle2295"></a>Suppose further that we determine (after careful scrutiny of the implementation) that each iteration of the inner loop requires <span class="docEmphasis">a</span><sub>0</sub> nanoseconds, the outer section requires <span class="docEmphasis">a</span><sub>1</sub> nanoseconds, and the initialization part <span class="docEmphasis">a</span><sub>2</sub> nanoseconds. Then we know that the average running time of the program (in nanoseconds) is</p>
<div class="docText"><pre>2a<sub>0</sub>NH<sub>N</sub> + a<sub>1</sub>N + a<sub>2</sub>:</pre></div><br />
<p class="docText">But it is also true that the running time is</p>
<div class="docText"><pre>2a<sub>0</sub>NH<sub>N</sub> + O(N):</pre></div><br />
<p class="docText">This simpler form is significant because it says that, for large <span class="docEmphasis">N</span>, we may not need to find the values of <span class="docEmphasis">a</span><sub>1</sub> or <span class="docEmphasis">a</span><sub>2</sub> to approximate the running time. In general, there could well be many other terms in the mathematical expression for the exact running time, some of which may be difficult to analyze. The <span class="docEmphasis">O</span>-notation provides us with a way to get an approximate answer for large <span class="docEmphasis">N</span> without bothering with such terms.</p>
<p class="docText">Continuing this example, we also can use the <span class="docEmphasis">O</span>-notation to express running time in terms of a familiar function, ln <span class="docEmphasis">N</span>. In terms of the <span class="docEmphasis">O</span>-notation, the approximation in <a class="docLink" href="ch02lev1sec3.html#ch02table03">Table 2.3</a> is expressed as <span class="docEmphasis">H</span><sub>N</sub> = ln <span class="docEmphasis">N</span> + <span class="docEmphasis">O</span>(1). Thus, <span class="docEmphasis">a</span><sub>0</sub><span class="docEmphasis">N</span> <span class="docEmphasis">ln</span> <span class="docEmphasis">N</span> + <span class="docEmphasis">O</span>(<span class="docEmphasis">N</span>) is an asymptotic expression for the total running time of our algorithm. We expect the running time to be close to the easily computed value 2<span class="docEmphasis">a</span><sub>0</sub><span class="docEmphasis">N</span> ln <span class="docEmphasis">N</span> for large <span class="docEmphasis">N</span>. The constant factor <span class="docEmphasis">a</span><sub>0</sub> depends on the time taken by the instructions in the inner loop.</p>
<p class="docText">Furthermore, we do not need to know the value of <span class="docEmphasis">a</span><sub>0</sub> to predict that the running time for input of size 2<span class="docEmphasis">N</span> will be about twice the running time for input of size <span class="docEmphasis">N</span> for huge <span class="docEmphasis">N</span> because</p>
<p class="docText">
<img border="0" alt="" width="400" height="34" src="046equ01.jpg" /></p>
<p class="docText">That is, the asymptotic formula allows us to make accurate predictions without concerning ourselves with details of either the implementation or the analysis. Note that such a prediction would <span class="docEmphasis">not</span> be possible if we were to have only an <span class="docEmphasis">O</span>-approximation for the leading term.</p>
<p class="docText">The kind of reasoning just outlined allows us to focus on the leading term when comparing or trying to predict the running times of algorithms. We are so often in the position of counting the number of times that fixed-cost operations are performed and wanting to use the leading term to estimate the result that we normally keep track of <a name="iddle1235"></a><a name="iddle1513"></a><a name="iddle1988"></a><span class="docEmphasis">only</span> the leading term, assuming implicitly that a precise analysis like the one just given could be performed, if necessary.</p>
<p class="docText">When a function <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>) is asymptotically large compared to another function <span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>) (that is, <span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>)/<span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>)<img src="U2192.GIF" border="0" /> 0 as <span class="docEmphasis">N</span> <img src="U2192.GIF" border="0" /> <img src="U221E.GIF" border="0" />), we sometimes use in this book the (decidedly nontechnical) terminology <span class="docEmphasis">about</span> <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>) to mean <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>)+<span class="docEmphasis">O</span>(<span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>)). What we seem to lose in mathematical precision we gain in clarity, for we are more interested in the performance of algorithms than in mathematical details. In such cases, we can rest assured that, for large <span class="docEmphasis">N</span> (if not for all <span class="docEmphasis">N</span>), the quantity in question will be close to <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>). For example, even if we know that a quantity is <span class="docEmphasis">N</span>(<span class="docEmphasis">N</span> &ndash; 1)/2, we may refer to it as being about <span class="docEmphasis">N</span><sup>2</sup>/2. This way of expressing the result is more quickly understood than the more detailed exact result, and, for example, deviates from the truth only by 0.1 percent for <span class="docEmphasis">N</span> = 1000. The precision lost in such cases pales by comparison with the precision lost in the more common usage <span class="docEmphasis">O</span>(<span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>)). Our goal is to be both precise and concise when describing the performance of algorithms.</p>
<p class="docText">In a similar vein, we sometimes say that the running time of an algorithm <span class="docEmphasis">is proportional to</span> <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>) when we can prove that it is equal to <span class="docEmphasis">cf</span>(<span class="docEmphasis">N</span>)+<span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>) with <span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>) asymptotically smaller than <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>). When this kind of bound holds, we can project the running time for, say, 2<span class="docEmphasis">N</span> from our observed running time for <span class="docEmphasis">N</span>, as in the example just discussed. <a class="docLink" href="#ch02fig03">Figure 2.3</a> gives the factors that we can use for such projection for functions that commonly arise in the analysis of algorithms. Coupled with empirical studies (see <a class="docLink" href="ch02lev1sec1.html#ch02lev1sec1">Section 2.1</a>), this approach frees us from the task of determining implementation-dependent constants in detail. Or, working backward, we often can easily develop an hypothesis about the functional growth of the running time of a program by determining the effect of doubling <span class="docEmphasis">N</span> on running time.</p>
<a name="ch02fig03"></a><p><center>
<h5 class="docFigureTitle">Figure 2.3. Effect of doubling problem size on running time</h5>
<h5></h5><h5></h5></center></p><p class="docText">Predicting the effect of doubling the problem size on the running time is a simple task when the running time is proportional to certain simple functions, as indicated in this table. In theory, we cannot depend on this effect unless <span class="docEmphasis">N</span> is huge, but this method is surprisingly effective. Conversely, a quick method for determining the functional growth of the running time of a program is to run that program empirically, doubling the input size for <span class="docEmphasis">N</span> as large as possible, then work backward from this table.</p>
<p class="docText">
<img border="0" alt="" width="200" height="147" src="02fig03.gif" /></p>
</td></tr></table></p><br />
<p class="docText">The distinctions among <span class="docEmphasis">O</span>-bounds, <span class="docEmphasis">is proportional to</span>, and <span class="docEmphasis">about</span> are illustrated in <a class="docLink" href="#ch02fig04">Figures 2.4</a> and <a class="docLink" href="#ch02fig05">2.5</a>. We use <span class="docEmphasis">O</span>-notation primarily to learn the fundamental asymptotic behavior of an algorithm; <span class="docEmphasis">is proportional to</span> when we want to predict performance by extrapolation from empirical studies; and <span class="docEmphasis">about</span> when we want to compare performance or to make absolute performance predictions.</p>
</td></tr></table>
<a name="ch02fig04"></a><p><center>
<h5 class="docFigureTitle">Figure 2.4. Bounding a function with an O-approximation</h5>
<h5></h5><h5></h5></center></p><p class="docText">In this schematic diagram, the oscillating curve represents a function, <span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>), which we are trying to approximate; the black smooth curve represents another function, <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>), which we are trying to use for the approximation; and the gray smooth curve represents <span class="docEmphasis">cf</span>(<span class="docEmphasis">N</span>) for some unspecified constant <span class="docEmphasis">c</span>. The vertical line represents a value <span class="docEmphasis">N</span><sub>0</sub>, indicating that the approximation is to hold for <span class="docEmphasis">N</span> &gt; <span class="docEmphasis">N</span><sub>0</sub>. When we say that <span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>) = <span class="docEmphasis">O</span>(<span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>)), we expect only that the value of <span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>) falls below <span class="docEmphasis">some</span> curve the shape of <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>) to the right of <span class="docEmphasis">some vertical line</span>. The behavior of f(N) could otherwise be erratic (for example, it need not even be continuous).</p>
<p class="docText">
<img border="0" alt="" width="150" height="123" src="02fig04.gif" /></p>
<br />
<a name="ch02fig05"></a><p><center>
<h5 class="docFigureTitle">Figure 2.5. Functional approximations</h5>
<h5></h5><h5></h5></center></p><p class="docText">When we say that <span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>) is proportional to <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>) (top), we expect that it eventually grows like <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>) does, but perhaps offset by an unknown constant. Given some value of <span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>), this knowledge allows us to estimate it for larger <span class="docEmphasis">N</span> When we say that <span class="docEmphasis">g</span>(<span class="docEmphasis">N</span>) is about <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>) (bottom), we expect that we can eventually use f to estimate the value of g accurately.</p>
<p class="docText">
<img border="0" alt="" width="175" height="255" src="02fig05.gif" /></p>
<br />
<p class="docQandasetTitle">Exercises</p><p><table border="0" cellspacing="16" cellpadding="0"><tr><td></td><td></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q1"></a><b></b></td><td><p class="docText"><img border="0" alt="" width="8" height="9" src="triangle.jpg" /> <span class="docEmphStrong">2.20</span> Prove that <span class="docEmphasis">O</span>(1) is the same as <span class="docEmphasis">O</span>(2).</p></td></tr><tr><td></td><td></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q2"></a><b></b></td><td><p class="docText"><a name="iddle1236"></a><a name="iddle1514"></a><a name="iddle1989"></a><span class="docEmphStrong">2.21</span> Prove that we can make any of the following transformations in an expression that uses the <span class="docEmphasis">O</span>-notation:</p>
<div class="docText"><pre>                       f(N) <img src="U2192.GIF" border="0" /> O(f(N));
                   cO(f(N)) <img src="U2192.GIF" border="0" /> O(f(N));
                   O(cf(N)) <img src="U2192.GIF" border="0" /> O(f(N));
f(N) &ndash; g(N) = O(h(N)) <img src="U2192.GIF" border="0" /> f(N) = g(N) + O(h(N));
             O(f(N))O(g(N)) <img src="U2192.GIF" border="0" /> O(f(N)g(N));
          O(f(N)) + O(g(N)) <img src="U2192.GIF" border="0" /> O(g(N))  if f(N) = O(g(N)):</pre></div><br /></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q3"></a><b></b></td><td><p class="docText"><img border="0" alt="" width="8" height="9" src="circle.jpg" />
<span class="docEmphStrong">2.22</span> Show that (<span class="docEmphasis">N</span> + 1)(<span class="docEmphasis">H</span><sub>N</sub> + <span class="docEmphasis">O</span>(1)) = <span class="docEmphasis">N</span> ln <span class="docEmphasis">N</span> + <span class="docEmphasis">O</span>(<span class="docEmphasis">N</span>).</p></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q4"></a><b></b></td><td><p class="docText"><span class="docEmphStrong">2.23</span> Show that <span class="docEmphasis">N</span> ln <span class="docEmphasis">N</span> = <span class="docEmphasis">O</span>(<span class="docEmphasis">N</span><sup>3/2</sup>).</p></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q5"></a><b></b></td><td><p class="docText"><img border="0" alt="" width="8" height="8" src="blackcircle.jpg" /> <span class="docEmphStrong">2.24</span> Show that <span class="docEmphasis">N</span><sup>M</sup> = <span class="docEmphasis">O</span> (&#945;<sup>N</sup>) for any <span class="docEmphasis">M</span> and any constant &#945; &gt; 1.</p></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q6"></a><b></b></td><td><p class="docText"><img border="0" alt="" width="8" height="8" src="blackcircle.jpg" /> <span class="docEmphStrong">2.25</span> Prove that</p>
<p class="docText">
<img border="0" alt="" width="135" height="29" src="048equ01.jpg" /></p>
</td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q7"></a><b></b></td><td><p class="docText"><span class="docEmphStrong">2.26</span> Suppose that <span class="docEmphasis">H</span><sub>k</sub> = <span class="docEmphasis">N</span>. Give an approximate formula that expresses <span class="docEmphasis">k</span> as a function of <span class="docEmphasis">N</span>.</p></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q8"></a><b></b></td><td><p class="docText"><img border="0" alt="" width="8" height="8" src="blackcircle.jpg" /> <span class="docEmphStrong">2.27</span> Suppose that lg(<span class="docEmphasis">k</span>!) = <span class="docEmphasis">N</span>. Give an approximate formula that expresses <span class="docEmphasis">k</span> as a function of <span class="docEmphasis">N</span>.</p></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q9"></a><b></b></td><td><p class="docText"><img border="0" alt="" width="8" height="9" src="circle.jpg" /> <span class="docEmphStrong">2.28</span> You are given the information that the running time of one algorithm is <span class="docEmphasis">O</span>(<span class="docEmphasis">N</span> <span class="docEmphRoman">log</span> <span class="docEmphasis">N</span>) and that the running time of another algorithm is <span class="docEmphasis">O</span>(<span class="docEmphasis">N</span><sup>3</sup>). What does this statement imply about the relative performance of the algorithms?</p></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q10"></a><b></b></td><td><p class="docText"><img border="0" alt="" width="8" height="9" src="circle.jpg" /> <span class="docEmphStrong">2.29</span> You are given the information that the running time of one algorithm is always about <span class="docEmphasis">N</span> <span class="docEmphRoman">log</span> <span class="docEmphasis">N</span> and that the running time of another algorithm is <span class="docEmphasis">O</span>(<span class="docEmphasis">N</span><sup>3</sup>). What does this statement imply about the relative performance of the algorithms?</p></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q11"></a><b></b></td><td><p class="docText"><img border="0" alt="" width="8" height="9" src="circle.jpg" /> <span class="docEmphStrong">2.30</span> You are given the information that the running time of one algorithm is always about <span class="docEmphasis">N</span> <span class="docEmphRoman">log</span> <span class="docEmphasis">N</span> and that the running time of another algorithm is always about <span class="docEmphasis">N</span><sup>3</sup>. What does this statement imply about the relative performance of the algorithms?</p></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q12"></a><b></b></td><td><p class="docText"><img border="0" alt="" width="8" height="9" src="circle.jpg" /> <span class="docEmphStrong">2.31</span> You are given the information that the running time of one algorithm is always proportional to <span class="docEmphasis">N</span> <span class="docEmphRoman">log</span> <span class="docEmphasis">N</span> and that the running time of another algorithm is always proportional to <span class="docEmphasis">N</span><sup>3</sup>. What does this statement imply about the relative performance of the algorithms?</p></td></tr><tr valign="top"><td align="right" class="docText" width="50"><a name="ch02qa4q13"></a><b></b></td><td><p class="docText"><img border="0" alt="" width="8" height="9" src="circle.jpg" /> <span class="docEmphStrong">2.32</span>Derive the factors given in <a class="docLink" href="#ch02fig03">Figure 2.3</a>: For each function <span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>) that appears on the left, find an asymptotic formula for <span class="docEmphasis">f</span>(2<span class="docEmphasis">N</span>)/<span class="docEmphasis">f</span>(<span class="docEmphasis">N</span>).</p>
</td></tr></table></p>
<ul></ul></div></td></tr></table><table width="100%" border="0" cellspacing="0" cellpadding="2"><tr><td valign="middle" class="v2" height="5"><img src="pixel.gif" width="1" height="5" alt="" border="0" /></td></tr><tr><td valign="middle" class="v2"><table cellpadding="0" cellspacing="0" border="0" width="100%"><tr><td align="left"><span style="white-space:nowrap">&nbsp;</span>
                  &nbsp;
                  <span style="white-space:nowrap"> &nbsp;&nbsp;</span>
            &nbsp;<span style="white-space:nowrap">&nbsp;</span></td></tr></table></td><td></td><td valign="middle" class="v2" align="right"> 
          &nbsp;
          <span style="white-space:nowrap"><a target="_self" href="ch02lev1sec3.html" title="Previous section"><img border="0" align="absmiddle" src="btn_prev.gif" alt="Previous section" id="btn_prev" /></a></span>
				
				&nbsp;
				
				<span style="white-space:nowrap"><a target="_self" href="ch02lev1sec5.html" title="Next section"><img border="0" align="absmiddle" src="btn_next.gif" alt="Next section" id="btn_next" /></a></span></td></tr></table><table width="100%" border="0" cellspacing="0" cellpadding="2"><tr><td valign="top" align="right"><span style="white-space:nowrap"><a target="_self" href="#toppage" title="Top"></a></span></td></tr></table><!--IP User 2--></td></body></head></html>